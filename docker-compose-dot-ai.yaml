# Docker Compose configuration for DevOps AI Toolkit MCP Server
# Development and testing deployment with MCP server + Qdrant

services:
  # DevOps AI Toolkit MCP Server
  dot-ai:
    image: ${DOT_AI_IMAGE:-ghcr.io/vfarcic/dot-ai:latest}
    container_name: dot-ai
    network_mode: "host"
    environment:
      # AI Provider Configuration
      # Options: anthropic (Sonnet 4.5), anthropic_haiku (Haiku 4.5)
      AI_PROVIDER: ${AI_PROVIDER:-anthropic_haiku}
      # Required: Anthropic API key for AI analysis
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      # Required: OpenAI API key for embeddings (capabilities, policies, patterns)
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      # Qdrant Vector Database connection
      QDRANT_URL: http://localhost:${QDRANT_PORT:-6333}
      # Kubernetes configuration - mount entire .kube directory for reliability
      # For GKE: uses token-based config-dot-ai (no gcloud plugin needed)
      # For Kind: uses default config (direct access)
      KUBECONFIG: /root/.kube/config-dot-ai
    volumes:
      # Mount entire .kube directory to avoid Docker directory creation issues
      - ~/.kube:/root/.kube:ro
    depends_on:
      - qdrant

  # Qdrant Vector Database
  qdrant:
    image: ${QDRANT_IMAGE:-qdrant/qdrant:latest}
    container_name: ${QDRANT_NAME:-qdrant}
    ports:
      - "${QDRANT_PORT:-6333}:6333"
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - dot-ai-network

volumes:
  qdrant_data:
    name: ${QDRANT_NAME:-qdrant}-data

networks:
  dot-ai-network:
    name: dot-ai-network